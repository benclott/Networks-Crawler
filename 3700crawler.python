#!/usr/bin/env python3

import argparse
import socket
import ssl
from html.parser import HTMLParser
import time
import sys
import urllib.parse

DEFAULT_SERVER = "proj5.3700.network"
DEFAULT_PORT = 443

class Crawler:
    def __init__(self, args):
        self.server = args.server
        self.port = args.port
        self.username = args.username
        self.password = args.password
    
    checkedPaths = [] #A list of tuples of checked paths

    #The cookies for this; they will in theory update every time so update at the start of each 200 or 302
    sessionId = '' #The sessionId cookie for this run provided from the first response
    csrfToken = '' #The csrf token for this run provided from the first response
    next  = ''
    middleware = '' #The middleware 
    needCookies = False

    def run(self):
        count = 0
        data = '' ##Store the data of the message
        
        while(1):
            sock = self.sockInit()
            sock.connect((self.server, self.port))
            print("\nStarting Loop at line 35, this is go around: " + str(count) + "\n")
            request = self.getPath(data)
            print("\nThe Request is\n" + str(request))
            sock.send(request.encode('ascii'))
            data = self.receive_message(sock)#
            #data = sock.recv(10000000).decode('ascii')
            #print("Response:\n%s" % data)
            count = count + 1
            sock.close()

    #Handle the work of the socket and wrapping so it's out of main
    ##return a socket
    def sockInit(self):
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        ssl_context = ssl.create_default_context()
        sock = ssl_context.wrap_socket(sock, server_hostname=self.server)
        return sock
   
    def receive_message(self, sock):
            # Read HTTP headers first
        response_headers = b""
        while not response_headers.endswith(b"\r\n\r\n"):
            data = sock.recv(1)  # Read one byte at a time to get headers
            if not data:
                break  # Connection closed
            response_headers += data
        
        headers = response_headers.decode('utf-8')
        print("Headers:\n", headers)
        
        # Check if the response is chunked
        if 'transfer-encoding: chunked' in headers.lower():
            response_body = self.read_chunked_body(sock)
        else:
            # If not chunked, use Content-Length to read the response body
            content_length = self.get_content_length(headers)
            response_body = b""
            if content_length:
                while len(response_body) < content_length:
                    data = sock.recv(content_length - len(response_body))
                    if not data:
                        break  # Connection closed
                    response_body += data

        print("Body:\n", response_body.decode('utf-8'))
        return headers + "\n" + response_body.decode('utf-8')

    def get_content_length(self, headers):
        for line in headers.split('\r\n'):
            if line.lower().startswith('content-length:'):
                return int(line.split(":")[1].strip())
        return None

    def read_chunked_body(self, sock):
        body = b""
        while True:
            chunk_size_str = b""
            char = b""
            while char != b"\r\n":
                char = sock.recv(2)
                if char == b"\r\n": break
                chunk_size_str += char
            chunk_size = int(chunk_size_str.split(b";")[0], 16)
            if chunk_size == 0:
                break  # End of chunks
            chunk = sock.recv(chunk_size)
            sock.recv(2)  # Consume trailing \r\n of the chunk
            body += chunk
        return body

    '''
    Method to handle the response of the server
    This is where we initialize and call the html library we have created
    Should be looped through in the run and all the magic of html understanding happens here
    will create the path to send the next request and then also the message
    '''
    def getPath(self, data):
        count = 0
        root = "/fakebook/"
        if data == '':
            return self.createGet(root, self.needCookies)
        else:

            
            #Compile the data that we have into usable information 
            brokenData = data.split("\n")
            responseCode = brokenData[0].split(' ')[1]
            header_end_index = data.find('\r\n\r\n')
            header = data[:header_end_index]
            html = data[header_end_index + 4:].strip()
            if count == 0:
                self.sessionId = self.getSessionId(header)
                self.csrfToken = self.getCSRF(header)
                count = count + 1 
            else:
                pass
            if responseCode == '200':
                self.sessionId = self.getSessionId(header)
                self.csrfToken = self.getCSRF(header)
                print("\nHandling 200 Request\n")
                self.needCookies = True
                return self.handle200(html, parser)
            elif responseCode == '302':
                print("\nHandling 302 Request")
                return self.handle302(brokenData)
            elif responseCode.startswith('4'):
                print("\nWe got a 400 error\n")
                print(data)
                sys.exit(0)
        

    '''
    Method to handle if we got a 200 response from the webpage
    This indicates that the webpage is loaded or the form sent was loaded correctly

    Handle Data from the html here and then dispatch
    
    '''
    def handle200(self, html, parser):
        parser = customHTML()
        #print("\nWe are now handling a 200, the html is \n" + str(html))
        parser.feed(html)
        
        if(parser.method == "GET"): #This means that we did not find a form that updated so we should deal with the links that are available
            #Should work on the path list from the parser
            print("|IN the path loopingn|")
            print("Self.next is " + self.next)
            print("Self.middleware is " + self.middleware)
            pathList = parser.paths
            for path in pathList:
                if path[0] == '/accounts/logout/':
                    path[1] = True
            for path in pathList:
                if path[1] == True:
                    pass
                    #Skip because we have already checked 
                else: #We haven't checked it
                    path[1] = True
                    print(self.csrfToken)
                    print(self.sessionId)
                    sock = self.sockInit()
                    sock.connect((self.server, self.port))
                    request = self.createGet(path[0], True)
                    print("This request is " + str(request))
                    sock.send(request.encode('ascii'))
                    data = self.receive_message(sock)
                    
                    print(data)
            print("AT THE END")
            return 
        else: #We need to send a post request so that we can login
            self.next = parser.next
            self.middleware = parser.crsfMiddleware
            return self.createPost("/accounts/login/")

        #return #Figure out to make this return something depending on the necessary request

    '''
    Method to handle if we get a redirect
    Should just take the new path provided in the http response and send a get request to load the new page
    '''
    def handle302(self, httpResponse):
        print("\nIn 302 method")
        redirectedPath = httpResponse[4].split(" ")[1].strip() # Extract the path from the response
        return self.createGet(redirectedPath, self.needCookies) # Return path that the server redirects us to

    '''
    Create a get request
    Should just be the same except for a given path that changes each time

    path boolean -> request

    Path: The path to send the request to
    Boolean: True if we need to include the sessionID and CSRF and false if we should not
    '''
    def createGet(self, path, needCookies):
        print(f'Sending a Get request, cookies are include = {needCookies}\n')
        if needCookies: #We need cookies so include the sessionID and CSRF
            return 'GET {} HTTP/1.1\r\nHost: {}:{}\r\nConnection: closed\r\nCookie: csrftoken={}; sessionid={}\r\n\r\n'.format(path, self.server, self.port, self.csrfToken, self.sessionId)
        else: #We do not need cookie so send a basic Get
            return 'GET {} HTTP/1.1\r\nHost: {}:{}\r\nConnection: closed\r\n\r\n'.format(path, self.server, self.port)

    def getSessionId(self, header):
        # Look for the start index of "sessionid="
        start_index = header.find("sessionid=")
        if start_index == -1:
            # If "sessionid=" is not found, return None or an appropriate value
            return None
        
        # Add the length of "sessionid=" to the start index to find where the session ID starts
        start_index += len("sessionid=")
        
        # Assume the session ID ends at the next semicolon or the end of the string if no semicolon is found
        end_index = header.find(";", start_index)
        if end_index == -1:
            # If no semicolon is found, the session ID goes until the end of the string
            end_index = len(header)

        
        
        # Extract and return the session ID
        return header[start_index:end_index]
    
    def getCSRF(self, header):
        # Look for the start index of "sessionid="
        start_index = header.find("csrftoken=")
        if start_index == -1:
            # If "sessionid=" is not found, return None or an appropriate value
            return None
        
        # Add the length of "sessionid=" to the start index to find where the session ID starts
        start_index += len("sessionid=")
        
        # Assume the session ID ends at the next semicolon or the end of the string if no semicolon is found
        end_index = header.find(";", start_index)
        if end_index == -1:
            # If no semicolon is found, the session ID goes until the end of the string
            end_index = len(header)

        
        
        # Extract and return the session ID
        return header[start_index:end_index]

    #Method to decide which server/host to send the website too
    def sendto(self):
        ##Check if args.s exissts
        s = args.server
        p = args.port
        if s == "proj5.3700.network" and p == 443:
            #The default has been provided so...
            return ("www.3700.network", 443)
        else:
            return (s, p)

    def createPost(self, path):
        httptype = "HTTP/1.0"
        #("csrf is" + str(self.csrf))
        if path == '/accounts/login/':
            body = f'username={self.username}&password={self.password}&csrfmiddlewaretoken={self.middleware}&next='
            headers = """Content-Type: application/x-www-form-urlencoded\nContent-Length: {}\nCookie: csrftoken={}; sessionid={}""".format(len(body), self.csrfToken,self.sessionId)

            request = 'POST {} HTTP/1.1\r\nHost: {}:{}\r\n{}\r\n\r\n{}'.format(
            path, self.server, self.port, headers, body)
        else:
            ##need to pull the headers and body from somewhere else
            request = 'POST {} HTTP/1.\r\nHost: {}:{}\r\n{}\r\n\r\n{}'.format(
            path, self.server, self.port, headers, body)
        return request

'''Create a custom HTML class that will identify and handle each problem'''
class customHTML(HTMLParser):
    def __init__(self):
        super().__init__()
        self.paths = [] # (Path, Boolean), (Path, Boolean), ... || True --> Path has been seen, False --> Path has not been seen
        self.flags = [] # If we find flags in html store them here
        self.flag_found = False # If current page finds a flag this becomes true
        self.crsfMiddleware = '' #The middleware token -> bad naming
        self.userRequest = False #Are we looking for a username
        self.passRequest = False #Are we looking for a password
        self.inForm = False #Boolean to store if we are in a form. used to then parse further tags 
        # = '' #Session id cookie pulled from the first request
        self.next = '' #The next which is required value for the path if logging 
        self.method = "GET"

    '''
    Look for start tags

    Figure out the start tag and then call the necessary next function
    will have base case for if everything is empty 
    '''
    def handle_starttag(self, tag, attrs):
        attrs = dict(attrs) #Create a dictionarry of the attributes and reset what attrs is so we can easily manipulate without massive iteration
        if tag == 'a': #If the tag is an anchor tag we may have to go to a link on the page
            self.handleLinks(attrs) 
        elif tag == 'h3': #We are in a secret
            self.handleSecrets(attrs)
        elif tag == 'form': #We have found a form tag and may need to send a Post or Get to submit a form
            self.inForm = True
            self.method = attrs.get('method', 'get').lower() #If we find a post then we will send that otherwise default to get
        elif tag == 'input' and self.inForm: #We have found input tags in a form to collect data from
            self.handleForm(tag, attrs)
        pass

    '''
    Handle Links = Extract the links from the html so we can know where to go next
    Saves everything to the class global var
    attributes -> None
    '''
    def handleLinks(self, attrs):
        href = attrs.get('href')
        if href and self.validURL(href):
            paths = {path for path, seen in self.paths}
            if href not in paths:
                self.paths.append([href, False])
    
    '''
    Handle secrets -> Add any flags that we find to the list of found flags and pretty much do nothing else

    attributes -> none
    '''
    def handleSecrets(self, attrs):
        if attrs.get('class') == 'secret_flag':
            self.flag_found = True
            print("I FOUND A FLAG")


    '''
    We need to handle inputs from a form to get important information like the csrfmiddleware token and if we need to actually send a post or a get

    attrs -> nothing

    Alters:
    userFound, passFound, sendPostNext (method), csrfMiddleWareToken, next
    '''
    def handleForm(self, tag, attrs):
        dict_attrs = dict(attrs)
        input_type = dict_attrs.get("type")
        input_name = dict_attrs.get("name")
        # Check for username field
        if input_type == "text" and input_name == "username":
            self.userRequest = True
        # Check for password field
        elif input_type == "password" and input_name == "password":
            self.passRequest = True
        # Extract CSRF token if present
        elif input_type == "hidden" and input_name == "csrfmiddlewaretoken":
            self.crsfMiddleware = dict_attrs.get("value")
        elif input_type == "hidden" and input_name == "next":
            self.next = dict_attrs.get("value")


    '''
        Returns true if the URL is valid and the path should be crawled.
        Returns false otherwise
    '''
    def validURL(self, url):
        # Assume base_url is the root URL of your target website
        base_url = "https://www.3700.network"
        base_netloc = urllib.parse.urlparse(base_url).netloc

        # Fully resolve relative URLs against the base_url
        full_url = urllib.parse.urljoin(base_url, url)
        parsed = urllib.parse.urlparse(full_url)

        # Now, parsed contains the full URL. You can check its netloc against your base netloc
        return parsed.netloc == base_netloc and parsed.scheme in ["http", "https"]
    '''
    We have reached the end of the tag so move on somehow and then recall handleState
    '''
    def handleEnd(self, tag):
        pass

    '''
    To be called inside the state tag
    Based on which function mpping it should do something 
    '''
    def handle_data(self, data):
        if self.flag_found == True:
            self.flag_content += data.strip()
            self.flags.append(self.flag_content)
            print(f'I ADDED THE FLAG {self.flag_content}')
            flag_found = False # set back to false so you can find the next one


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='crawl Fakebook')
    parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
    parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
    parser.add_argument('username', type=str, help="The username to use")
    parser.add_argument('password', type=str, help="The password to use")
    args = parser.parse_args()
    sender = Crawler(args)
    sender.run()


